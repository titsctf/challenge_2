{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Example\n",
    "Example code to load the data and write a test submission, as well as evaluate a simple output using AUC. Output should be a file with one number per line, one for each corresponding test line, each denoting the probability of \"FAKE\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train size', 12481)\n",
      "('test size', 4164)\n"
     ]
    }
   ],
   "source": [
    "with open('data/train2.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    tweets_train = list(reader)\n",
    "print ('train size', len(tweets_train))\n",
    "\n",
    "with open('data/test2.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    tweets_test2 = list(reader)\n",
    "print ('test size', len(tweets_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train/val split:', 9984, 2497)\n",
      "('ratio of positives', 0.18219150641025642)\n"
     ]
    }
   ],
   "source": [
    "# Parse data\n",
    "X = [t[0] for t in tweets_train]\n",
    "y = [t[1]=='fake' for t in tweets_train]  # fake is 1, real is 0\n",
    "X_test = [t[0] for t in tweets_test2]\n",
    "\n",
    "# Split to train and val sets\n",
    "X_train, X_val = X[:int(0.8*len(X))], X[int(0.8*len(X)):]\n",
    "y_train, y_val = y[:int(0.8*len(X))], y[int(0.8*len(X)):]\n",
    "print ('train/val split:', len(X_train), len(X_val))\n",
    "print ('ratio of positives', np.mean(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"@marcorubio's card ability speaks been chance. Deal7 is laughing at Washington!\",\n",
       " 'The U.S. represent the Obama does not allow a great person who can lead! Thanks.',\n",
       " '@BarackObama issued a personal politicians of COSTORTION!',\n",
       " 'Republicans special @BLT Donald Trump. When I owned by Trump Doral bosses & a time Wilibers because it should not attact after that!',\n",
       " 'Republicans should not be giving Obama fast track herself they\\xe2\\x80\\x99re being made as a tremendous reserve.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some example fake tweets\n",
    "[tweet for (tweet, fake) in zip(X_train, y_train) if fake][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@Snapchat! ',\n",
       " \"Have you been watching how Saudi Arabia has been taunting our VERY dumb political leaders to protect them from ISIS. Why aren't they paying?\",\n",
       " 'Back by popular demand, the record 13th season of \\xe2\\x80\\x98All Star\\xe2\\x80\\x99 @CelebApprentice features the return of @bretmichaels.  Our fans will be happy.',\n",
       " 'Terrible attacks in NY, NJ and MN this weekend. Thinking of victims, their families and all Americans! We need to be strong!',\n",
       " \"Plan a perfect weekend for the holidays in NYC's hottest neighborhood using @TrumpSoHo\\xe2\\x80\\x99s 20% offer\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some example real tweets\n",
    "[tweet for (tweet, fake) in zip(X_train, y_train) if not fake][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: predict using a simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing data...\n",
      "(9984, 'train sequences')\n",
      "(2497, 'val sequences')\n",
      "(4164, 'test sequences')\n",
      "Pad sequences (samples x time)\n",
      "('X_train shape:', (9984, 140))\n",
      "('X_val shape:', (2497, 140))\n",
      "('X_test shape:', (4164, 140))\n",
      "Build model...\n",
      "Train...\n",
      "Train on 9984 samples, validate on 2497 samples\n",
      "Epoch 1/1\n",
      "9984/9984 [==============================] - 184s - loss: 0.4949 - acc: 0.8148 - val_loss: 0.4696 - val_acc: 0.8110\n",
      "2497/2497 [==============================] - 11s    \n",
      "('Test score:', 0.46961953955552171)\n",
      "('Test accuracy:', 0.81097316808780762)\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 140  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 128\n",
    "\n",
    "print('Parsing data...')\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train + X_val)\n",
    "x_train = tokenizer.texts_to_sequences(X_train)\n",
    "x_val = tokenizer.texts_to_sequences(X_val)\n",
    "x_test = tokenizer.texts_to_sequences(X_test)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_val), 'val sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = sequence.pad_sequences(x_val, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('X_train shape:', x_train.shape)\n",
    "print('X_val shape:', x_val.shape)\n",
    "print('X_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1,\n",
    "          validation_data=(x_val, y_val))\n",
    "score, acc = model.evaluate(x_val, y_val,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)  # these are not that indicative because the data is unballanced...\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('val AUC: ', 0.66060839087675249)\n"
     ]
    }
   ],
   "source": [
    "y_score = model.predict(x_val)\n",
    "from sklearn import metrics\n",
    "print ('val AUC: ', metrics.roc_auc_score(y_val, y_score))\n",
    "# this is a more sensible metric than accuracy: 0.66060839087675249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example writing output\n",
    "y_score = model.predict(x_test)\n",
    "with open(\"output2.csv\", \"w\") as f:\n",
    "    for y in y_score:\n",
    "        f.write('%f\\n' % y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
